{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import dirname, abspath, join\n",
    "from os import getcwd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "THIS_DIR = getcwd()\n",
    "CLASS_DIR = abspath(join(THIS_DIR, '../../..', 'dsnclasses'))\n",
    "sys.path.append(CLASS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ENOsmall import ENO\n",
    "from CAPMr2 import CAPM\n",
    "from NN3 import Net, DQN\n",
    "from globalvar import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 99:  TOKYO, 2010 \n",
      "Best Average Reward \t=   -2.795\n",
      "Average Reward \t\t=   -3.608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-3, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TRAIN USING data from TOKYO, WAKKANAI and MINAMIDAITO FROM 2005 to 2014\n",
    "dqn = DQN()\n",
    "\n",
    "NO_OF_ITERATIONS = 100\n",
    "best_avg_reward = -1000 #initialize best average reward to very low value\n",
    "PFILENAME = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(8)) #create random filename\n",
    "BFILENAME = \"best\"+PFILENAME + \".pt\" #this file stores the best model\n",
    "TFILENAME = \"terminal\"+PFILENAME + \".pt\" #this file stores the last model\n",
    "\n",
    "avg_reward_rec = [] #record the yearly average rewards over the entire duration of training\n",
    "print('\\nTRAINING IN PROGRESS')\n",
    "\n",
    "for iteration in range(NO_OF_ITERATIONS):\n",
    "    LOCATION = random.choice(['tokyo','wakkanai','minamidaito'])\n",
    "    YEAR = random.choice(np.arange(2005,2015))\n",
    "    capm = CAPM(LOCATION,YEAR,shuffle=True, trainmode=True) #instantiate the CAPM class\n",
    "    capm.eno = ENO(LOCATION,YEAR, shuffle=True, day_balance=True) #instantiate the environment inside the CAPM class\n",
    "    capm.HMAX = capm.eno.SMAX #maximum power output of solar cell is set in CAPM object using the value in ENO object\n",
    "    clear_output()\n",
    "    print('\\nIteration {}:  {}, {} '.format(iteration, LOCATION.upper(), YEAR))\n",
    "    print(\"Best Average Reward \\t= {:8.3f}\".format(best_avg_reward))\n",
    "\n",
    "\n",
    "    s, r, day_end, year_end = capm.reset()\n",
    "    record = np.empty(4) #record for battery, henergy, reward and action\n",
    "\n",
    "    transition_rec = np.zeros((capm.eno.TIME_STEPS, N_STATES * 2 + 2)) #record all the transition in one day\n",
    "\n",
    "    while True:\n",
    "        a = dqn.choose_action(s)\n",
    "        \n",
    "        # present state = [batt, enp, henergy]\n",
    "        record = np.vstack((record, [s[0],s[2],r, a])) # record battery, henergy, reward and action for troubleshooting\n",
    "                                                       # However, we are interested only in the reward\n",
    "\n",
    "        # take action\n",
    "        s_, r, day_end, year_end = capm.step(a)\n",
    "\n",
    "        temp_transitions = np.hstack((s, [a, r], s_))\n",
    "        transition_rec[capm.eno.hr-1,:] = temp_transitions\n",
    "\n",
    "        if (day_end):\n",
    "            transition_rec[:,5] = r #broadcast reward to all states\n",
    "            decay_factor = [i for i in (LAMBDA**n for n in reversed(range(0, capm.eno.TIME_STEPS)))]\n",
    "            transition_rec[:,5] = transition_rec[:,5] * decay_factor #decay reward proportionately\n",
    "            dqn.store_day_transition(transition_rec)\n",
    "\n",
    "        if dqn.memory_counter > MEMORY_CAPACITY:\n",
    "            dqn.learn()\n",
    "\n",
    "        if (year_end):\n",
    "#             print(\"End of Year\")\n",
    "            break\n",
    "        \n",
    "        # transition to new state\n",
    "        s = s_\n",
    "\n",
    "    record = np.delete(record, 0, 0) #remove the first row which is garbage\n",
    "    reward_rec = record[:,2]\n",
    "    reward_rec = reward_rec[reward_rec != 0] #remove all zero rewards in the middle of the days\n",
    "    print(\"Average Reward \\t\\t= {:8.3f}\".format(np.mean(reward_rec)))\n",
    "    \n",
    "    # Check if reward beats the High Score and possible save it    \n",
    "    if(best_avg_reward < np.mean(reward_rec)):\n",
    "        best_avg_reward = np.mean(reward_rec)\n",
    "        if (iteration > 20): #save the best models only after 20 iterations\n",
    "            print(\"Saving Model\")\n",
    "            torch.save(dqn.eval_net.state_dict(), BFILENAME)\n",
    "\n",
    "    # Log the average reward in avg_reward_rec\n",
    "    avg_reward_rec = np.append(avg_reward_rec, np.mean(reward_rec))\n",
    "    \n",
    "# End of training\n",
    "# Save the last model\n",
    "torch.save(dqn.eval_net.state_dict(), TFILENAME) \n",
    "\n",
    "# Plot the average reward log\n",
    "plt.plot(avg_reward_rec,'b')\n",
    "plt.ylim([-3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BFILENAME -> loads the best model\n",
    "#TFILENAME -> loads the last model\n",
    "MODELFILE = TFILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the trained model for using greedy policy\n",
    "TEST_LOCATION = 'tokyo'\n",
    "TEST_YEAR = 2015\n",
    "print('\\nYear run test')\n",
    "\n",
    "dqn = DQN()\n",
    "capm = CAPM(TEST_LOCATION,TEST_YEAR, shuffle=False, trainmode=False)\n",
    "capm.eno = ENO(TEST_LOCATION,TEST_YEAR, shuffle=False, day_balance=False) #instantiate the environment inside the CAPM class\n",
    "capm.HMAX = capm.eno.SMAX #maximum power output of solar cell is set in CAPM object using the value in ENO object\n",
    "\n",
    "\n",
    "# load the required model\n",
    "dqn.eval_net.load_state_dict(torch.load(MODELFILE))\n",
    "dqn.eval_net.eval()\n",
    "print('Model Used: ',MODELFILE)\n",
    "\n",
    "s, r, day_end, year_end = capm.reset()\n",
    "yr_test_record = np.empty(4)\n",
    "\n",
    "while True:\n",
    "    a = dqn.choose_greedy_action(s)\n",
    "\n",
    "    #state = [batt, enp, henergy, fcast]\n",
    "    yr_test_record = np.vstack((yr_test_record, [s[0],s[2],r, a])) #record battery, henergy, reward and action\n",
    "\n",
    "    # take action\n",
    "    s_, r, day_end, year_end = capm.step(a)\n",
    "\n",
    "    if year_end:\n",
    "        print(\"End of Test\")\n",
    "        break\n",
    "       \n",
    "    s = s_\n",
    "\n",
    "yr_test_record = np.delete(yr_test_record, 0, 0) #remove the first row which is garbage\n",
    "\n",
    "#Plot the reward and battery for the entire year run\n",
    "title = TEST_LOCATION.upper() + ',' + str(TEST_YEAR)\n",
    "\n",
    "NO_OF_DAYS = capm.eno.NO_OF_DAYS\n",
    "yr_test_reward_rec = yr_test_record[:,2]\n",
    "yr_test_reward_rec = yr_test_reward_rec[yr_test_reward_rec != 0]\n",
    "print('Average Reward for',title, '=', np.mean(yr_test_reward_rec))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(24,10))\n",
    "fig.suptitle(title, fontsize=15)\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(yr_test_reward_rec)\n",
    "ax1.set_title(\"\\n\\nYear Run Reward\")\n",
    "ax1.set_ylim([-3,1])\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.plot(yr_test_record[:,0],'r')\n",
    "ax2.set_title(\"Year Run Battery\")\n",
    "ax2.set_ylim([0,1])\n",
    "plt.sca(ax2)\n",
    "plt.xticks(np.arange(0, NO_OF_DAYS*24, 50*24),np.arange(0,NO_OF_DAYS,50))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot the reward and battery for the entire year run on a day by day basis\n",
    "\n",
    "# TIME_AXIS = np.arange(0,capm.eno.TIME_STEPS)\n",
    "# for DAY in range(0,10):#capm.eno.NO_OF_DAYS):\n",
    "#     START = DAY*24\n",
    "#     END = START+24\n",
    "    \n",
    "#     daytitle = title + ' - DAY ' + str(DAY)\n",
    "#     fig = plt.figure(figsize=(16,4))\n",
    "#     st = fig.suptitle(daytitle)\n",
    "\n",
    "#     ax2 = fig.add_subplot(121)\n",
    "#     ax2.plot(yr_test_record[START:END,1],'g')\n",
    "#     ax2.set_title(\"HARVESTED ENERGY\")\n",
    "#     plt.xlabel(\"Hour\")\n",
    "#     ax2.set_ylim([0,1])\n",
    "\n",
    "#     #plot battery for year run\n",
    "#     ax1 = fig.add_subplot(122)\n",
    "#     ax1.plot(TIME_AXIS,yr_test_record[START:END,0],'r') \n",
    "# #     ax1.plot(TIME_AXIS, np.ones(capm.eno.TIME_STEPS)*capm.BOPT/capm.BMAX,'r--')\n",
    "#     ax1.plot(TIME_AXIS, np.ones(capm.eno.TIME_STEPS)*yr_test_record[START,0],'r--')\n",
    "#     ax1.text(0.1, 0.2, \"BINIT = %.2f\\n\" %(yr_test_record[START,0]),fontsize=11, ha='left')\n",
    "#     ax1.text(0.1, 0.4, \"TENP = %.2f\\n\" %(capm.BOPT/capm.BMAX-yr_test_record[END,0]),fontsize=11, ha='left')\n",
    "#     ax1.text(0.1, 0.3, \"BMEAN = %.2f\\n\" %(np.mean(yr_test_record[START:END,0])),fontsize=11, ha='left')\n",
    "\n",
    "\n",
    "\n",
    "#     ax1.set_title(\"YEAR RUN TEST\")\n",
    "#     if END < (capm.eno.NO_OF_DAYS*capm.eno.TIME_STEPS):\n",
    "#         ax1.text(0.1, 0, \"REWARD = %.2f\\n\" %(yr_test_record[END,2]),fontsize=13, ha='left')\n",
    "#     plt.xlabel(\"Hour\")\n",
    "#     ax1.set_ylabel('Battery', color='r',fontsize=12)\n",
    "#     ax1.set_ylim([0,1])\n",
    "\n",
    "#     #plot actions for year run\n",
    "#     ax1a = ax1.twinx()\n",
    "#     ax1a.plot(yr_test_record[START:END,3])\n",
    "#     ax1a.set_ylim([0,N_ACTIONS])\n",
    "#     ax1a.set_ylabel('Duty Cycle', color='b',fontsize=12)\n",
    "    \n",
    "#     fig.tight_layout()\n",
    "#     st.set_y(0.95)\n",
    "#     fig.subplots_adjust(top=0.75)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
